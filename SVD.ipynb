{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "from torchtext.vocab import build_vocab_from_iterator,Vocab\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score,accuracy_score,confusion_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import scipy as sp\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_CUTOFF=3\n",
    "UNKNOWN_TOKEN='<unk>'\n",
    "WINDOW_SIZE=5\n",
    "BATCH_SIZE=128\n",
    "EMBEDDING_SIZE_SVD=300\n",
    "PAD_TOKEN='<pad>'\n",
    "NUM_LABELS=4\n",
    "HIDDEN_SIZE=128\n",
    "lrate=1e-3\n",
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/train.csv')\n",
    "train_labels=df['Class Index'].tolist()\n",
    "df=df['Description']\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sentences=[]\n",
    "for sent in df:\n",
    "    tokenizer=RegexpTokenizer(r'\\w+')\n",
    "    tokens=tokenizer.tokenize(sent)\n",
    "    tokens=[token.lower() for token in tokens]\n",
    "    sentences.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_low_frequency_words(sentences, threshold=UNK_CUTOFF):\n",
    "    word_counts = Counter(word for sentence in sentences for word in sentence)\n",
    "    replaced_sentences = [\n",
    "        [UNKNOWN_TOKEN if word_counts[word] < threshold else word for word in sentence]\n",
    "        for sentence in sentences\n",
    "    ]\n",
    "    return replaced_sentences\n",
    "sentences=replace_low_frequency_words(sentences)\n",
    "vocab_svd=build_vocab_from_iterator(sentences, specials=[UNKNOWN_TOKEN,PAD_TOKEN])\n",
    "vocab_svd.set_default_index(vocab_svd[UNKNOWN_TOKEN])\n",
    "co_occurrence_matrix=sp.sparse.lil_matrix((len(vocab_svd),len(vocab_svd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_list in sentences:\n",
    "        for i, word in enumerate(word_list):\n",
    "            center_index = vocab_svd[word]\n",
    "            context_indices = [vocab_svd[word_list[j]] for j in range(max(0, i - WINDOW_SIZE), min(len(word_list), i + WINDOW_SIZE + 1)) if i!=j]\n",
    "            for context_index in context_indices:\n",
    "                co_occurrence_matrix[center_index,context_index] += 1\n",
    "U,_,_=sp.sparse.linalg.svds(co_occurrence_matrix, EMBEDDING_SIZE_SVD, return_singular_vectors='u', which='LM')\n",
    "embeddings_SVD=U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings_SVD,'svd_word_vectors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_svd=torch.load('svd_word_vectors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_LSTM(Dataset):\n",
    "  def __init__(self, sent, labs, embeddings, vocabulary):\n",
    "    self.sentences = sent\n",
    "    self.labels = labs\n",
    "    self.vocabulary = vocabulary\n",
    "    self.embeddings=embeddings\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.sentences)\n",
    "  def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    word_embeddings=[self.embeddings[self.vocabulary[j]] for j in self.sentences[index]]\n",
    "    return torch.tensor(word_embeddings,dtype=torch.float32), torch.tensor(torch.nn.functional.one_hot(torch.tensor(self.labels[index]-1), num_classes=NUM_LABELS)).float()\n",
    "  def collate(self, batch: list[tuple[torch.Tensor, torch.Tensor]]) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    sentences = [i[0] for i in batch]\n",
    "    labels = [i[1] for i in batch]\n",
    "    padded_sentences = pad_sequence(sentences, batch_first=True, padding_value=self.vocabulary[PAD_TOKEN])\n",
    "    padded_labels=padded_labels = pad_sequence(labels, batch_first=True, padding_value=torch.tensor(0))\n",
    "    return padded_sentences, padded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/test.csv')\n",
    "test_labels=df['Class Index'].tolist()\n",
    "df=df['Description']\n",
    "test_sentences=[]\n",
    "for sent in df:\n",
    "    tokenizer=RegexpTokenizer(r'\\w+')\n",
    "    tokens=tokenizer.tokenize(sent)\n",
    "    tokens=[token.lower() for token in tokens]\n",
    "    test_sentences.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=Dataset_LSTM(sentences,train_labels,embeddings_SVD,vocab_svd)\n",
    "test_dataset=Dataset_LSTM(test_sentences,test_labels,embeddings_SVD,vocab_svd)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,shuffle=True,collate_fn=train_dataset.collate)\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=BATCH_SIZE,collate_fn=test_dataset.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2label = torch.nn.Linear(hidden_dim, num_classes)\n",
    "    def forward(self, sentence):\n",
    "        lstm_out, _ = self.lstm(sentence)\n",
    "        tag_space = self.hidden2label(lstm_out[-1])\n",
    "        tag_scores = torch.softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4764.482236921787\n",
      "Epoch 2, Loss: 3594.3006317019463\n",
      "Epoch 3, Loss: 3463.311684846878\n",
      "Epoch 4, Loss: 3379.8793036341667\n",
      "Epoch 5, Loss: 3352.7804537415504\n",
      "Epoch 6, Loss: 3332.8128027915955\n",
      "Epoch 7, Loss: 3311.2320789694786\n",
      "Epoch 8, Loss: 3294.139129459858\n",
      "Epoch 9, Loss: 3283.313927948475\n",
      "Epoch 10, Loss: 3267.174511373043\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(EMBEDDING_SIZE_SVD, HIDDEN_SIZE, NUM_LABELS)\n",
    "model=model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lrate)\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch_sentences, batch_labels in train_dataloader:\n",
    "        (batch_sentences, batch_labels) = (batch_sentences.to(device), batch_labels.to(device))\n",
    "        outputs = model(batch_sentences.permute(1,0,2))\n",
    "        loss = loss_fn(outputs, batch_labels)\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for train set :\n",
      "Accuracy Score: 0.8759833333333333\n",
      "F1_Score (Macro): 0.8757692587965115\n",
      "F1_Score (Micro): 0.8759833333333333\n",
      "Precision Score: 0.8777963602869505\n",
      "Recall Score: 0.8759833333333333\n",
      "Confusion Matrix:\n",
      " [[26022  1166  1415  1397]\n",
      " [  558 28523   191   728]\n",
      " [ 1272   472 23946  4310]\n",
      " [ 1361   496  1516 26627]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions=[]\n",
    "true_vals=[]\n",
    "with torch.no_grad():\n",
    "    for words, tags in train_dataloader:\n",
    "        (words, tags) = (words.to(device), tags.to(device))\n",
    "        pred = model(words.permute(1,0,2))\n",
    "        pred_max_index = torch.argmax(pred, dim=1)+1\n",
    "        true_vals.extend((torch.argmax(tags, dim=1)+1).cpu())\n",
    "        predictions.extend(pred_max_index.cpu())\n",
    "predictions=torch.stack(predictions).numpy()\n",
    "true_vals=torch.stack(true_vals).numpy()\n",
    "print('Evaluation Metrics for train set :')\n",
    "print(f'Accuracy Score: {accuracy_score(true_vals,predictions)}')\n",
    "print(f'F1_Score (Macro): {f1_score(true_vals,predictions, average='macro')}')\n",
    "print(f'F1_Score (Micro): {f1_score(true_vals,predictions, average='micro')}')\n",
    "print(f'Precision Score: {precision_score(true_vals,predictions, average='weighted')}')\n",
    "print(f'Recall Score: {recall_score(true_vals,predictions, average='weighted')}')\n",
    "print(f'Confusion Matrix:\\n {confusion_matrix(true_vals,predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for test set :\n",
      "Accuracy Score: 0.8602631578947368\n",
      "F1_Score (Macro): 0.859842356834317\n",
      "F1_Score (Micro): 0.8602631578947368\n",
      "Precision Score: 0.8619504569432361\n",
      "Recall Score: 0.8602631578947368\n",
      "Confusion Matrix:\n",
      " [[1628   75   96  101]\n",
      " [  47 1791   21   41]\n",
      " [ 105   36 1457  302]\n",
      " [  85   34  119 1662]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions=[]\n",
    "true_vals=[]\n",
    "with torch.no_grad():\n",
    "    for words, tags in test_dataloader:\n",
    "        (words, tags) = (words.to(device), tags.to(device))\n",
    "        pred = model(words.permute(1,0,2))\n",
    "        pred_max_index = torch.argmax(pred, dim=1)+1\n",
    "        true_vals.extend((torch.argmax(tags, dim=1)+1).cpu())\n",
    "        predictions.extend(pred_max_index.cpu())\n",
    "predictions=torch.stack(predictions).numpy()\n",
    "true_vals=torch.stack(true_vals).numpy()\n",
    "print('Evaluation Metrics for test set :')\n",
    "print(f'Accuracy Score: {accuracy_score(true_vals,predictions)}')\n",
    "print(f'F1_Score (Macro): {f1_score(true_vals,predictions, average='macro')}')\n",
    "print(f'F1_Score (Micro): {f1_score(true_vals,predictions, average='micro')}')\n",
    "print(f'Precision Score: {precision_score(true_vals,predictions, average='weighted')}')\n",
    "print(f'Recall Score: {recall_score(true_vals,predictions, average='weighted')}')\n",
    "print(f'Confusion Matrix:\\n {confusion_matrix(true_vals,predictions)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
